{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c19731b",
   "metadata": {
    "papermill": {
     "duration": 0.003236,
     "end_time": "2025-10-03T14:29:21.689949",
     "exception": false,
     "start_time": "2025-10-03T14:29:21.686713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction to Machine Learning - Practical Assignment 2\n",
    "## Questions 2 & 3 across 5 datasets (10x10 CV + T-tests)\n",
    "\n",
    "This notebook runs:\n",
    "- Question 2: 8 algorithms (no L1 NN) on 5 datasets using 10x10 CV.\n",
    "- Question 3: Paired t-tests per dataset (WIN/TIE/LOSS matrices) and overall aggregation.\n",
    "\n",
    "Datasets used (from `limited` folder):\n",
    "- Taiwan Bankruptcy (Binary bankruptcy prediction)\n",
    "- Breast Cancer (Binary cancer diagnosis: M/B)\n",
    "- Biodegradation (Binary biodegradability prediction)\n",
    "- Autism Screening (Binary autism diagnosis)\n",
    "- Student Data (Binary academic performance prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "047bd8ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T14:29:21.697297Z",
     "iopub.status.busy": "2025-10-03T14:29:21.696939Z",
     "iopub.status.idle": "2025-10-03T14:29:26.137514Z",
     "shell.execute_reply": "2025-10-03T14:29:26.136381Z"
    },
    "papermill": {
     "duration": 4.446769,
     "end_time": "2025-10-03T14:29:26.139801",
     "exception": false,
     "start_time": "2025-10-03T14:29:21.693032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: Imports, setup, and Kaggle/Colab notes\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For Colab (commented):\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# base_path = '/content/drive/MyDrive/imlpa2/data'\n",
    "\n",
    "# For Local:\n",
    "# base_path = 'limited'\n",
    "\n",
    "# For Kaggle\n",
    "base_path = '/kaggle/input/binarylimited'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24f4d5bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T14:29:26.147873Z",
     "iopub.status.busy": "2025-10-03T14:29:26.147339Z",
     "iopub.status.idle": "2025-10-03T14:29:26.289999Z",
     "shell.execute_reply": "2025-10-03T14:29:26.288465Z"
    },
    "papermill": {
     "duration": 0.149263,
     "end_time": "2025-10-03T14:29:26.292025",
     "exception": false,
     "start_time": "2025-10-03T14:29:26.142762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autism-Adult-Data.csv  breastcancer.csv  taiwanesebankruptcyprediction.csv\r\n",
      "biodeg.csv\t       student_data.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/binarylimited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed4aee5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T14:29:26.299466Z",
     "iopub.status.busy": "2025-10-03T14:29:26.299123Z",
     "iopub.status.idle": "2025-10-03T14:29:26.440648Z",
     "shell.execute_reply": "2025-10-03T14:29:26.439253Z"
    },
    "papermill": {
     "duration": 0.147375,
     "end_time": "2025-10-03T14:29:26.442351",
     "exception": false,
     "start_time": "2025-10-03T14:29:26.294976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Taiwan Bankruptcy...\n",
      "Loading Breast Cancer...\n",
      "Loading Biodegradation...\n",
      "Loading Autism Screening...\n",
      "Loading Student Data...\n",
      "- Taiwan_Bankruptcy: samples=500, features=95, classes=2\n",
      "- Breast_Cancer: samples=500, features=30, classes=2\n",
      "- Biodegradation: samples=500, features=41, classes=2\n",
      "- Autism_Screening: samples=500, features=91, classes=2\n",
      "- Student_Data: samples=500, features=36, classes=2\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: Load and preprocess all datasets\n",
    "# =============================================================================\n",
    "\n",
    "def load_all_datasets(base_path: str):\n",
    "    datasets = {}\n",
    "\n",
    "    print(\"Loading Taiwan Bankruptcy...\")\n",
    "    taiwan = pd.read_csv(f\"{base_path}/taiwanesebankruptcyprediction.csv\")\n",
    "    y_taiwan = taiwan.iloc[:, 0]\n",
    "    X_taiwan = taiwan.iloc[:, 1:]\n",
    "    datasets['Taiwan_Bankruptcy'] = (X_taiwan, y_taiwan)\n",
    "\n",
    "    print(\"Loading Breast Cancer...\")\n",
    "    bc = pd.read_csv(f\"{base_path}/breastcancer.csv\")\n",
    "    bc['Diagnosis'] = (bc['Diagnosis'] == 'M').astype(int)\n",
    "    X_bc = bc[[c for c in bc.columns if c not in ['ID', 'Diagnosis']]]\n",
    "    y_bc = bc['Diagnosis']\n",
    "    datasets['Breast_Cancer'] = (X_bc, y_bc)\n",
    "\n",
    "    print(\"Loading Biodegradation...\")\n",
    "    biodeg = pd.read_csv(f\"{base_path}/biodeg.csv\")\n",
    "    X_biodeg = biodeg.iloc[:, :-1]\n",
    "    y_biodeg = biodeg.iloc[:, -1]\n",
    "    datasets['Biodegradation'] = (X_biodeg, y_biodeg)\n",
    "\n",
    "    print(\"Loading Autism Screening...\")\n",
    "    autism = pd.read_csv(f\"{base_path}/Autism-Adult-Data.csv\")\n",
    "    X_autism = autism.iloc[:, :-1]\n",
    "    y_autism = autism.iloc[:, -1]\n",
    "    datasets['Autism_Screening'] = (X_autism, y_autism)\n",
    "\n",
    "    print(\"Loading Student Data...\")\n",
    "    student = pd.read_csv(f\"{base_path}/student_data.csv\")\n",
    "    X_student = student.iloc[:, :-1]\n",
    "    y_student = student.iloc[:, -1]\n",
    "    datasets['Student_Data'] = (X_student, y_student)\n",
    "\n",
    "    for name, (Xn, yn) in datasets.items():\n",
    "        print(f\"- {name}: samples={Xn.shape[0]}, features={Xn.shape[1]}, classes={len(np.unique(yn))}\")\n",
    "\n",
    "    return datasets\n",
    "\n",
    "all_datasets = load_all_datasets(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26155a0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T14:29:26.449779Z",
     "iopub.status.busy": "2025-10-03T14:29:26.449432Z",
     "iopub.status.idle": "2025-10-03T14:29:26.458466Z",
     "shell.execute_reply": "2025-10-03T14:29:26.456892Z"
    },
    "papermill": {
     "duration": 0.014792,
     "end_time": "2025-10-03T14:29:26.460375",
     "exception": false,
     "start_time": "2025-10-03T14:29:26.445583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithms:\n",
      " - Decision Tree (C4.5)\n",
      " - Decision Tree (CART)\n",
      " - SVM (Linear)\n",
      " - SVM (RBF Kernel)\n",
      " - Naive Bayes\n",
      " - Logistic Regression\n",
      " - 3-Layer NN\n",
      " - 3-Layer NN (L2)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: Define algorithms (without L1 NN)\n",
    "# =============================================================================\n",
    "\n",
    "def get_algorithms():\n",
    "    return {\n",
    "        'Decision Tree (C4.5)': DecisionTreeClassifier(criterion='entropy', random_state=42),\n",
    "        'Decision Tree (CART)': DecisionTreeClassifier(criterion='gini', random_state=42),\n",
    "        'SVM (Linear)': SVC(kernel='linear', random_state=42, probability=True),\n",
    "        'SVM (RBF Kernel)': SVC(kernel='rbf', random_state=42, probability=True),\n",
    "        'Naive Bayes': GaussianNB(),\n",
    "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        '3-Layer NN': MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42, max_iter=1000),\n",
    "        '3-Layer NN (L2)': MLPClassifier(hidden_layer_sizes=(100, 50), alpha=0.01, random_state=42, max_iter=1000),\n",
    "    }\n",
    "\n",
    "algorithms = get_algorithms()\n",
    "print(\"Algorithms:\")\n",
    "for k in algorithms.keys():\n",
    "    print(\" -\", k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d48636d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T14:29:26.468596Z",
     "iopub.status.busy": "2025-10-03T14:29:26.467644Z",
     "iopub.status.idle": "2025-10-03T14:29:26.487131Z",
     "shell.execute_reply": "2025-10-03T14:29:26.485934Z"
    },
    "papermill": {
     "duration": 0.025522,
     "end_time": "2025-10-03T14:29:26.488923",
     "exception": false,
     "start_time": "2025-10-03T14:29:26.463401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: 10x10 CV evaluation utilities and saving 10x10 tables\n",
    "# =============================================================================\n",
    "\n",
    "def evaluate_algorithm(X, y, algorithm, algorithm_name, return_grid=False):\n",
    "    run_accuracies, run_f1s, run_aucs = [], [], []\n",
    "    acc_grid = np.zeros((10, 10))  # 10 runs x 10 folds\n",
    "    f1_grid = np.zeros((10, 10))\n",
    "    auc_grid = np.zeros((10, 10))\n",
    "    \n",
    "    for run_idx in range(10):\n",
    "        run_fold_accs, run_fold_f1s, run_fold_aucs = [], [], []\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=run_idx)\n",
    "        for fold_idx, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            \n",
    "            if hasattr(y, 'iloc'):\n",
    "                y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "            else:\n",
    "                y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            imputer = SimpleImputer(strategy='mean')\n",
    "            X_train_scaled = imputer.fit_transform(X_train_scaled)\n",
    "            X_test_scaled = imputer.transform(X_test_scaled)\n",
    "\n",
    "            try:\n",
    "                if algorithm_name in ['SVM (Linear)', 'SVM (RBF Kernel)', 'Logistic Regression', '3-Layer NN', '3-Layer NN (L2)']:\n",
    "                    algorithm.fit(X_train_scaled, y_train)\n",
    "                    y_pred = algorithm.predict(X_test_scaled)\n",
    "                    y_proba = algorithm.predict_proba(X_test_scaled)\n",
    "                else:\n",
    "                    algorithm.fit(X_train, y_train)\n",
    "                    y_pred = algorithm.predict(X_test)\n",
    "                    y_proba = algorithm.predict_proba(X_test)\n",
    "            \n",
    "                acc = accuracy_score(y_test, y_pred)\n",
    "                f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            \n",
    "                auc = 0.0\n",
    "                unique_classes = np.unique(y)\n",
    "                unique_test_classes = np.unique(y_test)\n",
    "                if len(unique_classes) == 2:\n",
    "                    auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "                elif len(unique_test_classes) == len(unique_classes):\n",
    "                    auc = roc_auc_score(y_test, y_proba, multi_class='ovr', average='weighted')\n",
    "                else:\n",
    "                    auc = np.nan\n",
    "            \n",
    "                run_fold_accs.append(acc)\n",
    "                run_fold_f1s.append(f1)\n",
    "                run_fold_aucs.append(auc)\n",
    "            \n",
    "                acc_grid[run_idx, fold_idx] = acc\n",
    "                f1_grid[run_idx, fold_idx] = f1\n",
    "                auc_grid[run_idx, fold_idx] = auc\n",
    "            except Exception as e:\n",
    "                print(f\"Error in {algorithm_name}: {str(e)}\")\n",
    "                run_fold_accs.append(0.0)\n",
    "                run_fold_f1s.append(0.0)\n",
    "                run_fold_aucs.append(np.nan)\n",
    "            \n",
    "        if len(run_fold_accs) > 0:\n",
    "            run_accuracies.append(float(np.mean(run_fold_accs)))\n",
    "            run_f1s.append(float(np.mean(run_fold_f1s)))\n",
    "            run_aucs.append(float(np.mean(run_fold_aucs)))\n",
    "    \n",
    "    summary = {\n",
    "        'accuracy': float(np.mean(run_accuracies)),\n",
    "        'f1_score': float(np.mean(run_f1s)),\n",
    "        'auc': float(np.mean(run_aucs)),\n",
    "        'std_accuracy': float(np.std(run_accuracies)),\n",
    "        'std_f1': float(np.std(run_f1s)),\n",
    "        'std_auc': float(np.std(run_aucs)),\n",
    "    }\n",
    "    if return_grid:\n",
    "        return summary, acc_grid, f1_grid, auc_grid\n",
    "    return summary\n",
    "\n",
    "    safe_ds = dataset_name.replace(' ', '_')\n",
    "\n",
    "def save_metric_grids(dataset_name, algorithm_name, acc_grid, f1_grid, auc_grid):\n",
    "    safe_alg = algorithm_name.replace(' ', '_').replace('(', '').replace(')', '')\n",
    "    safe_ds = dataset_name.replace(' ', '_')\n",
    "\n",
    "    safe_ds = dataset_name.replace(' ', '_')\n",
    "    pd.DataFrame(acc_grid).to_csv(f\"{safe_ds}__{safe_alg}__acc_grid.csv\", index=False)\n",
    "    safe_alg = algorithm_name.replace(' ', '_').replace('(', '').replace(')', '')\n",
    "\n",
    "    safe_alg = algorithm_name.replace(' ', '_').replace('(', '').replace(')', '')\n",
    "    pd.DataFrame(f1_grid).to_csv(f\"{safe_ds}__{safe_alg}__f1_grid.csv\", index=False)\n",
    "    pd.DataFrame(acc_grid).to_csv(f\"{safe_ds}__{safe_alg}__acc_grid.csv\", index=False)    \n",
    "    pd.DataFrame(auc_grid).to_csv(f\"{safe_ds}__{safe_alg}__auc_grid.csv\", index=False)\n",
    "\n",
    "    pd.DataFrame(acc_grid).to_csv(f\"{safe_ds}__{safe_alg}__acc_grid.csv\", index=False)\n",
    "    pd.DataFrame(auc_grid).to_csv(f\"{safe_ds}__{safe_alg}__auc_grid.csv\", index=False)\n",
    "    pd.DataFrame(f1_grid).to_csv(f\"{safe_ds}__{safe_alg}__f1_grid.csv\", index=False)    \n",
    "    pd.DataFrame(auc_grid).to_csv(f\"{safe_ds}__{safe_alg}__auc_grid.csv\", index=False)\n",
    "\n",
    "    pd.DataFrame(f1_grid).to_csv(f\"{safe_ds}__{safe_alg}__f1_grid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1c9775d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T14:29:26.496273Z",
     "iopub.status.busy": "2025-10-03T14:29:26.495910Z",
     "iopub.status.idle": "2025-10-03T14:45:09.149844Z",
     "shell.execute_reply": "2025-10-03T14:45:09.148444Z"
    },
    "papermill": {
     "duration": 942.665009,
     "end_time": "2025-10-03T14:45:09.156965",
     "exception": false,
     "start_time": "2025-10-03T14:29:26.491956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET: Taiwan_Bankruptcy\n",
      "============================================================\n",
      "- Decision Tree (C4.5)\n",
      "  Acc 0.9488±0.0065 | F1 0.9474±0.0060 | AUC 0.7691±0.0294\n",
      "- Decision Tree (CART)\n",
      "  Acc 0.9442±0.0067 | F1 0.9430±0.0068 | AUC 0.7588±0.0310\n",
      "- SVM (Linear)\n",
      "  Acc 0.9424±0.0055 | F1 0.9404±0.0053 | AUC 0.8449±0.0103\n",
      "- SVM (RBF Kernel)\n",
      "  Acc 0.9370±0.0018 | F1 0.9093±0.0024 | AUC 0.9081±0.0057\n",
      "- Naive Bayes\n",
      "  Acc 0.8480±0.0403 | F1 0.8354±0.0370 | AUC 0.5791±0.0144\n",
      "- Logistic Regression\n",
      "  Acc 0.9498±0.0038 | F1 0.9451±0.0040 | AUC 0.8641±0.0101\n",
      "- 3-Layer NN\n",
      "  Acc 0.9546±0.0036 | F1 0.9461±0.0039 | AUC 0.8463±0.0135\n",
      "- 3-Layer NN (L2)\n",
      "  Acc 0.9550±0.0038 | F1 0.9465±0.0042 | AUC 0.8475±0.0134\n",
      "\n",
      "============================================================\n",
      "DATASET: Breast_Cancer\n",
      "============================================================\n",
      "- Decision Tree (C4.5)\n",
      "  Acc 0.9246±0.0064 | F1 0.9246±0.0064 | AUC 0.9221±0.0067\n",
      "- Decision Tree (CART)\n",
      "  Acc 0.9252±0.0109 | F1 0.9250±0.0110 | AUC 0.9212±0.0117\n",
      "- SVM (Linear)\n",
      "  Acc 0.9756±0.0012 | F1 0.9755±0.0012 | AUC 0.9941±0.0014\n",
      "- SVM (RBF Kernel)\n",
      "  Acc 0.9748±0.0020 | F1 0.9747±0.0021 | AUC 0.9945±0.0009\n",
      "- Naive Bayes\n",
      "  Acc 0.9368±0.0022 | F1 0.9363±0.0022 | AUC 0.9869±0.0010\n",
      "- Logistic Regression\n",
      "  Acc 0.9796±0.0032 | F1 0.9795±0.0033 | AUC 0.9946±0.0009\n",
      "- 3-Layer NN\n",
      "  Acc 0.9760±0.0038 | F1 0.9759±0.0038 | AUC 0.9934±0.0018\n",
      "- 3-Layer NN (L2)\n",
      "  Acc 0.9754±0.0039 | F1 0.9753±0.0039 | AUC 0.9934±0.0019\n",
      "\n",
      "============================================================\n",
      "DATASET: Biodegradation\n",
      "============================================================\n",
      "- Decision Tree (C4.5)\n",
      "  Acc 0.8276±0.0070 | F1 0.8266±0.0070 | AUC 0.8232±0.0071\n",
      "- Decision Tree (CART)\n",
      "  Acc 0.8252±0.0135 | F1 0.8246±0.0136 | AUC 0.8216±0.0142\n",
      "- SVM (Linear)\n",
      "  Acc 0.8820±0.0073 | F1 0.8815±0.0073 | AUC 0.9330±0.0045\n",
      "- SVM (RBF Kernel)\n",
      "  Acc 0.8798±0.0027 | F1 0.8796±0.0028 | AUC 0.9464±0.0029\n",
      "- Naive Bayes\n",
      "  Acc 0.8184±0.0039 | F1 0.8113±0.0038 | AUC 0.9090±0.0017\n",
      "- Logistic Regression\n",
      "  Acc 0.8808±0.0024 | F1 0.8801±0.0025 | AUC 0.9362±0.0035\n",
      "- 3-Layer NN\n",
      "  Acc 0.8942±0.0073 | F1 0.8941±0.0073 | AUC 0.9448±0.0048\n",
      "- 3-Layer NN (L2)\n",
      "  Acc 0.8936±0.0070 | F1 0.8934±0.0071 | AUC 0.9445±0.0048\n",
      "\n",
      "============================================================\n",
      "DATASET: Autism_Screening\n",
      "============================================================\n",
      "- Decision Tree (C4.5)\n",
      "  Acc 1.0000±0.0000 | F1 1.0000±0.0000 | AUC 1.0000±0.0000\n",
      "- Decision Tree (CART)\n",
      "  Acc 1.0000±0.0000 | F1 1.0000±0.0000 | AUC 1.0000±0.0000\n",
      "- SVM (Linear)\n",
      "  Acc 0.9948±0.0016 | F1 0.9947±0.0016 | AUC 0.9992±0.0011\n",
      "- SVM (RBF Kernel)\n",
      "  Acc 0.9260±0.0048 | F1 0.9240±0.0051 | AUC 0.9700±0.0036\n",
      "- Naive Bayes\n",
      "  Acc 0.2928±0.0041 | F1 0.2261±0.0077 | AUC 0.4992±0.0049\n",
      "- Logistic Regression\n",
      "  Acc 0.9760±0.0051 | F1 0.9758±0.0052 | AUC 0.9942±0.0018\n",
      "- 3-Layer NN\n",
      "  Acc 0.9486±0.0037 | F1 0.9487±0.0037 | AUC 0.9857±0.0026\n",
      "- 3-Layer NN (L2)\n",
      "  Acc 0.9482±0.0034 | F1 0.9483±0.0034 | AUC 0.9859±0.0025\n",
      "\n",
      "============================================================\n",
      "DATASET: Student_Data\n",
      "============================================================\n",
      "- Decision Tree (C4.5)\n",
      "  Acc 0.8306±0.0101 | F1 0.8298±0.0097 | AUC 0.8094±0.0093\n",
      "- Decision Tree (CART)\n",
      "  Acc 0.8226±0.0101 | F1 0.8226±0.0098 | AUC 0.8029±0.0103\n",
      "- SVM (Linear)\n",
      "  Acc 0.9242±0.0048 | F1 0.9229±0.0046 | AUC 0.9479±0.0039\n",
      "- SVM (RBF Kernel)\n",
      "  Acc 0.8858±0.0056 | F1 0.8795±0.0058 | AUC 0.9227±0.0031\n",
      "- Naive Bayes\n",
      "  Acc 0.8376±0.0049 | F1 0.8352±0.0044 | AUC 0.8610±0.0053\n",
      "- Logistic Regression\n",
      "  Acc 0.9164±0.0045 | F1 0.9144±0.0047 | AUC 0.9466±0.0021\n",
      "- 3-Layer NN\n",
      "  Acc 0.9004±0.0065 | F1 0.8989±0.0069 | AUC 0.9116±0.0057\n",
      "- 3-Layer NN (L2)\n",
      "  Acc 0.9002±0.0075 | F1 0.8988±0.0079 | AUC 0.9116±0.0057\n",
      "\n",
      "Summary: Taiwan_Bankruptcy\n",
      "           Algorithm Average Accuracy Average F-Measure     Average AUC\n",
      "     3-Layer NN (L2)  0.9550 ± 0.0038   0.9465 ± 0.0042 0.8475 ± 0.0134\n",
      "          3-Layer NN  0.9546 ± 0.0036   0.9461 ± 0.0039 0.8463 ± 0.0135\n",
      " Logistic Regression  0.9498 ± 0.0038   0.9451 ± 0.0040 0.8641 ± 0.0101\n",
      "Decision Tree (C4.5)  0.9488 ± 0.0065   0.9474 ± 0.0060 0.7691 ± 0.0294\n",
      "Decision Tree (CART)  0.9442 ± 0.0067   0.9430 ± 0.0068 0.7588 ± 0.0310\n",
      "        SVM (Linear)  0.9424 ± 0.0055   0.9404 ± 0.0053 0.8449 ± 0.0103\n",
      "    SVM (RBF Kernel)  0.9370 ± 0.0018   0.9093 ± 0.0024 0.9081 ± 0.0057\n",
      "         Naive Bayes  0.8480 ± 0.0403   0.8354 ± 0.0370 0.5791 ± 0.0144\n",
      "\n",
      "Summary: Breast_Cancer\n",
      "           Algorithm Average Accuracy Average F-Measure     Average AUC\n",
      " Logistic Regression  0.9796 ± 0.0032   0.9795 ± 0.0033 0.9946 ± 0.0009\n",
      "          3-Layer NN  0.9760 ± 0.0038   0.9759 ± 0.0038 0.9934 ± 0.0018\n",
      "        SVM (Linear)  0.9756 ± 0.0012   0.9755 ± 0.0012 0.9941 ± 0.0014\n",
      "     3-Layer NN (L2)  0.9754 ± 0.0039   0.9753 ± 0.0039 0.9934 ± 0.0019\n",
      "    SVM (RBF Kernel)  0.9748 ± 0.0020   0.9747 ± 0.0021 0.9945 ± 0.0009\n",
      "         Naive Bayes  0.9368 ± 0.0022   0.9363 ± 0.0022 0.9869 ± 0.0010\n",
      "Decision Tree (CART)  0.9252 ± 0.0109   0.9250 ± 0.0110 0.9212 ± 0.0117\n",
      "Decision Tree (C4.5)  0.9246 ± 0.0064   0.9246 ± 0.0064 0.9221 ± 0.0067\n",
      "\n",
      "Summary: Biodegradation\n",
      "           Algorithm Average Accuracy Average F-Measure     Average AUC\n",
      "          3-Layer NN  0.8942 ± 0.0073   0.8941 ± 0.0073 0.9448 ± 0.0048\n",
      "     3-Layer NN (L2)  0.8936 ± 0.0070   0.8934 ± 0.0071 0.9445 ± 0.0048\n",
      "        SVM (Linear)  0.8820 ± 0.0073   0.8815 ± 0.0073 0.9330 ± 0.0045\n",
      " Logistic Regression  0.8808 ± 0.0024   0.8801 ± 0.0025 0.9362 ± 0.0035\n",
      "    SVM (RBF Kernel)  0.8798 ± 0.0027   0.8796 ± 0.0028 0.9464 ± 0.0029\n",
      "Decision Tree (C4.5)  0.8276 ± 0.0070   0.8266 ± 0.0070 0.8232 ± 0.0071\n",
      "Decision Tree (CART)  0.8252 ± 0.0135   0.8246 ± 0.0136 0.8216 ± 0.0142\n",
      "         Naive Bayes  0.8184 ± 0.0039   0.8113 ± 0.0038 0.9090 ± 0.0017\n",
      "\n",
      "Summary: Autism_Screening\n",
      "           Algorithm Average Accuracy Average F-Measure     Average AUC\n",
      "Decision Tree (C4.5)  1.0000 ± 0.0000   1.0000 ± 0.0000 1.0000 ± 0.0000\n",
      "Decision Tree (CART)  1.0000 ± 0.0000   1.0000 ± 0.0000 1.0000 ± 0.0000\n",
      "        SVM (Linear)  0.9948 ± 0.0016   0.9947 ± 0.0016 0.9992 ± 0.0011\n",
      " Logistic Regression  0.9760 ± 0.0051   0.9758 ± 0.0052 0.9942 ± 0.0018\n",
      "          3-Layer NN  0.9486 ± 0.0037   0.9487 ± 0.0037 0.9857 ± 0.0026\n",
      "     3-Layer NN (L2)  0.9482 ± 0.0034   0.9483 ± 0.0034 0.9859 ± 0.0025\n",
      "    SVM (RBF Kernel)  0.9260 ± 0.0048   0.9240 ± 0.0051 0.9700 ± 0.0036\n",
      "         Naive Bayes  0.2928 ± 0.0041   0.2261 ± 0.0077 0.4992 ± 0.0049\n",
      "\n",
      "Summary: Student_Data\n",
      "           Algorithm Average Accuracy Average F-Measure     Average AUC\n",
      "        SVM (Linear)  0.9242 ± 0.0048   0.9229 ± 0.0046 0.9479 ± 0.0039\n",
      " Logistic Regression  0.9164 ± 0.0045   0.9144 ± 0.0047 0.9466 ± 0.0021\n",
      "          3-Layer NN  0.9004 ± 0.0065   0.8989 ± 0.0069 0.9116 ± 0.0057\n",
      "     3-Layer NN (L2)  0.9002 ± 0.0075   0.8988 ± 0.0079 0.9116 ± 0.0057\n",
      "    SVM (RBF Kernel)  0.8858 ± 0.0056   0.8795 ± 0.0058 0.9227 ± 0.0031\n",
      "         Naive Bayes  0.8376 ± 0.0049   0.8352 ± 0.0044 0.8610 ± 0.0053\n",
      "Decision Tree (C4.5)  0.8306 ± 0.0101   0.8298 ± 0.0097 0.8094 ± 0.0093\n",
      "Decision Tree (CART)  0.8226 ± 0.0101   0.8226 ± 0.0098 0.8029 ± 0.0103\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: Run Question 2 for all datasets, save summaries and 10x10 tables\n",
    "# =============================================================================\n",
    "\n",
    "dataset_results = {}\n",
    "for dataset_name, (Xd, yd) in all_datasets.items():\n",
    "    print(f\"\\n{'='*60}\\nDATASET: {dataset_name}\\n{'='*60}\")\n",
    "    dataset_results[dataset_name] = {}\n",
    "    for alg_name, alg in get_algorithms().items():\n",
    "        print(f\"- {alg_name}\")\n",
    "        from sklearn.base import clone\n",
    "        alg_copy = clone(alg)\n",
    "        summary, acc_grid, f1_grid, auc_grid = evaluate_algorithm(Xd, yd, alg_copy, alg_name, return_grid=True)\n",
    "        dataset_results[dataset_name][alg_name] = summary\n",
    "        save_metric_grids(dataset_name, alg_name, acc_grid, f1_grid, auc_grid)\n",
    "        print(f\"  Acc {summary['accuracy']:.4f}±{summary['std_accuracy']:.4f} | F1 {summary['f1_score']:.4f}±{summary['std_f1']:.4f} | AUC {summary['auc']:.4f}±{summary['std_auc']:.4f}\")\n",
    "\n",
    "for dataset_name, alg_metrics in dataset_results.items():\n",
    "    rows = []\n",
    "    for alg_name, m in alg_metrics.items():\n",
    "        rows.append({\n",
    "            'Algorithm': alg_name,\n",
    "            'Average Accuracy': f\"{m['accuracy']:.4f} ± {m['std_accuracy']:.4f}\",\n",
    "            'Average F-Measure': f\"{m['f1_score']:.4f} ± {m['std_f1']:.4f}\",\n",
    "            'Average AUC': f\"{m['auc']:.4f} ± {m['std_auc']:.4f}\",\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['Acc_Value'] = [float(x.split(' ±')[0]) for x in df['Average Accuracy']]\n",
    "    df = df.sort_values('Acc_Value', ascending=False).drop('Acc_Value', axis=1)\n",
    "    print(f\"\\nSummary: {dataset_name}\")\n",
    "    print(df.to_string(index=False))\n",
    "    df.to_csv(f\"{dataset_name}__summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61fb95e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T14:45:09.169239Z",
     "iopub.status.busy": "2025-10-03T14:45:09.168926Z",
     "iopub.status.idle": "2025-10-03T14:45:09.849961Z",
     "shell.execute_reply": "2025-10-03T14:45:09.848527Z"
    },
    "papermill": {
     "duration": 0.689192,
     "end_time": "2025-10-03T14:45:09.851579",
     "exception": false,
     "start_time": "2025-10-03T14:45:09.162387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting t-test analysis using saved grid files...\n",
      "\n",
      "Processing t-tests for: Taiwan_Bankruptcy\n",
      "\n",
      "Processing t-tests for: Breast_Cancer\n",
      "\n",
      "Processing t-tests for: Biodegradation\n",
      "\n",
      "Processing t-tests for: Autism_Screening\n",
      "\n",
      "Processing t-tests for: Student_Data\n",
      "\n",
      "Generating overall WIN-TIE-LOSS summary...\n",
      "           Algorithm Decision Tree (C4.5) Decision Tree (CART) SVM (Linear) SVM (RBF Kernel) Naive Bayes Logistic Regression 3-Layer NN 3-Layer NN (L2)\n",
      "Decision Tree (C4.5)                    —               0-15-0       4-1-10           5-0-10       8-2-5              3-2-10     3-1-11          3-1-11\n",
      "Decision Tree (CART)               0-15-0                    —       2-3-10           5-0-10       7-1-7              3-1-11     3-1-11          3-1-11\n",
      "        SVM (Linear)               10-1-4               10-3-2            —            8-5-2      15-0-0               5-6-4      6-5-4           6-4-5\n",
      "    SVM (RBF Kernel)               10-0-5               10-0-5        2-5-8                —      15-0-0              2-3-10      2-4-9           2-4-9\n",
      "         Naive Bayes                5-2-8                7-1-7       0-0-15           0-0-15           —              0-0-15     0-0-15          0-0-15\n",
      " Logistic Regression               10-2-3               11-1-3        4-6-5           10-3-2      15-0-0                   —      8-3-4           7-4-4\n",
      "          3-Layer NN               11-1-3               11-1-3        4-5-6            9-4-2      15-0-0               4-3-8          —          0-14-1\n",
      "     3-Layer NN (L2)               11-1-3               11-1-3        5-4-6            9-4-2      15-0-0               4-4-7     1-14-0               —\n",
      "\n",
      "Done. All CSV outputs are saved in the working directory.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: Question 3 - T-tests using saved grid files\n",
    "# =============================================================================\n",
    "\n",
    "def load_metric_grids(dataset_name, algorithm_name):\n",
    "    \"\"\"Load the saved 10x10 grid files for a dataset/algorithm pair\"\"\"\n",
    "    safe_ds = dataset_name.replace(' ', '_')\n",
    "    safe_alg = algorithm_name.replace(' ', '_').replace('(', '').replace(')', '')\n",
    "    \n",
    "    try:\n",
    "        acc_grid = pd.read_csv(f\"{safe_ds}__{safe_alg}__acc_grid.csv\").values\n",
    "        f1_grid = pd.read_csv(f\"{safe_ds}__{safe_alg}__f1_grid.csv\").values\n",
    "        auc_grid = pd.read_csv(f\"{safe_ds}__{safe_alg}__auc_grid.csv\").values\n",
    "        \n",
    "        acc_means = np.mean(acc_grid, axis=1)  \n",
    "        f1_means = np.mean(f1_grid, axis=1)\n",
    "        auc_means = np.mean(auc_grid, axis=1)\n",
    "        \n",
    "        return {\n",
    "            'accuracies': acc_means.tolist(),\n",
    "            'f1_scores': f1_means.tolist(),\n",
    "            'auc_scores': auc_means.tolist()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading grids for {dataset_name} - {algorithm_name}: {str(e)}\")\n",
    "        return {\n",
    "            'accuracies': [0.0] * 10,\n",
    "            'f1_scores': [0.0] * 10, \n",
    "            'auc_scores': [0.0] * 10\n",
    "        }\n",
    "\n",
    "def collect_fold_scores_from_files(dataset_name):\n",
    "    \"\"\"Collect algorithm scores from saved grid files instead of re-running\"\"\"\n",
    "    results = {}\n",
    "    for alg_name in get_algorithms().keys():\n",
    "        results[alg_name] = load_metric_grids(dataset_name, alg_name)\n",
    "    return results\n",
    "\n",
    "def create_ttest_matrix(algorithm_fold_results, metric='accuracies', alpha=0.05):\n",
    "    \"\"\"Create WIN/TIE/LOSS matrix from fold results using paired t-test\"\"\"\n",
    "    names = list(algorithm_fold_results.keys())\n",
    "    n = len(names)\n",
    "    win = np.zeros((n, n))\n",
    "    tie = np.zeros((n, n))\n",
    "    loss = np.zeros((n, n))\n",
    "    \n",
    "    for i, a in enumerate(names):\n",
    "        for j, b in enumerate(names):\n",
    "            if i == j:\n",
    "                tie[i, j] = 1\n",
    "                continue\n",
    "            r1 = algorithm_fold_results[a][metric]\n",
    "            r2 = algorithm_fold_results[b][metric]\n",
    "            \n",
    "            t, p = stats.ttest_rel(r1, r2)\n",
    "            if p < alpha:\n",
    "                if np.mean(r1) > np.mean(r2):\n",
    "                    win[i, j] = 1\n",
    "                    loss[j, i] = 1\n",
    "                else:\n",
    "                    loss[i, j] = 1\n",
    "                    win[j, i] = 1\n",
    "            else:\n",
    "                tie[i, j] = 1\n",
    "                tie[j, i] = 1\n",
    "    return win, tie, loss, names\n",
    "\n",
    "# Process each dataset\n",
    "print(\"Starting t-test analysis using saved grid files...\")\n",
    "datasets = list(all_datasets.keys())\n",
    "overall_wtl = {}\n",
    "alg_names_ref = None\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    print(f\"\\nProcessing t-tests for: {dataset_name}\")\n",
    "    \n",
    "    fold_scores = collect_fold_scores_from_files(dataset_name)\n",
    "    \n",
    "    w_acc, t_acc, l_acc, names = create_ttest_matrix(fold_scores, 'accuracies')\n",
    "    w_f1, t_f1, l_f1, _ = create_ttest_matrix(fold_scores, 'f1_scores')\n",
    "    w_auc, t_auc, l_auc, _ = create_ttest_matrix(fold_scores, 'auc_scores')\n",
    "    \n",
    "    if alg_names_ref is None:\n",
    "        alg_names_ref = names\n",
    "        \n",
    "    def save_matrix(prefix, w, t, l):\n",
    "        pd.DataFrame(w, index=names, columns=names).to_csv(f\"{dataset_name}__{prefix}__win.csv\")\n",
    "        pd.DataFrame(t, index=names, columns=names).to_csv(f\"{dataset_name}__{prefix}__tie.csv\")\n",
    "        pd.DataFrame(l, index=names, columns=names).to_csv(f\"{dataset_name}__{prefix}__loss.csv\")\n",
    "    \n",
    "    save_matrix('ACC', w_acc, t_acc, l_acc)\n",
    "    save_matrix('F1', w_f1, t_f1, l_f1)\n",
    "    save_matrix('AUC', w_auc, t_auc, l_auc)\n",
    "    \n",
    "    for i, ai in enumerate(names):\n",
    "        for j, aj in enumerate(names):\n",
    "            if i == j:\n",
    "                continue\n",
    "            key = (ai, aj)\n",
    "            if key not in overall_wtl:\n",
    "                overall_wtl[key] = {'W': 0, 'T': 0, 'L': 0}\n",
    "            \n",
    "            for w, t, l in [(w_acc, t_acc, l_acc), (w_f1, t_f1, l_f1), (w_auc, t_auc, l_auc)]:\n",
    "                if w[i, j] == 1:\n",
    "                    overall_wtl[key]['W'] += 1\n",
    "                elif l[i, j] == 1:\n",
    "                    overall_wtl[key]['L'] += 1\n",
    "                elif t[i, j] == 1:\n",
    "                    overall_wtl[key]['T'] += 1\n",
    "\n",
    "print(\"\\nGenerating overall WIN-TIE-LOSS summary...\")\n",
    "rows = []\n",
    "for i, ai in enumerate(alg_names_ref):\n",
    "    row = {'Algorithm': ai}\n",
    "    for j, aj in enumerate(alg_names_ref):\n",
    "        if i == j:\n",
    "            row[aj] = '—'\n",
    "        else:\n",
    "            wtl = overall_wtl.get((ai, aj), {'W': 0, 'T': 0, 'L': 0})\n",
    "            row[aj] = f\"{wtl['W']}-{wtl['T']}-{wtl['L']}\"\n",
    "    rows.append(row)\n",
    "\n",
    "overall_df = pd.DataFrame(rows)\n",
    "print(overall_df.to_string(index=False))\n",
    "overall_df.to_csv('OVERALL_WTL.csv', index=False)\n",
    "print(\"\\nDone. All CSV outputs are saved in the working directory.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8392937,
     "sourceId": 13251564,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 955.292694,
   "end_time": "2025-10-03T14:45:10.681102",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-03T14:29:15.388408",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
